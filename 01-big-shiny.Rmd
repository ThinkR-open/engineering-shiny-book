\mainmatter

# (PART) Building Successful Shiny Apps {-}

# About Successful Shiny Apps {#successfulshinyapp}

> I Too Like to Live Dangerously

`r right_align("Austin Powers")`

## A (very) short introduction to Shiny 

If you are reading this page, chances are you already know what a Shiny application (shorten "Shiny app") is—a web application that communicates with R, built in R, and working with R. 
The beauty of `{shiny}` [@R-shiny] is that it makes it easy for someone already familiar with R to create a small app in a matter of hours.
With small and minimal Shiny apps, no knowledge of HTML, CSS or JavaScript is required, and you do not have to think about technical elements that usually come with web applications—for example, you do not have to think about the port the application is served on: `{shiny}` picks one for you
^[Of course you can specify one if you need to, but by default the package picks one;]
.
Same goes for serving external dependencies: the application comes with its set of CSS and JavaScript dependencies that a common Shiny developer does not need to worry about. 
And that is probably one of the main reason why this package has become so successful over the years—with very little training, you can rapidly create a proof-of-concept (PoC) for a data-product, showcase an algorithm, or present your results in an elegant and accessible user interface. 

The first version of `{shiny}` was published in 2012. 
Since then, it has been one of the top project of the RStudio team. 
At the time of writing these lines (April 2020), there are more than 4700 commits in the master branch of the GitHub repository, made by 46 contributors. 
It is now downloaded around 400K times a month, according to [cranlogs](https://cranlogs.r-pkg.org/badges/shiny), and has `r length(devtools::revdep("shiny"))` reverse dependencies (i.e packages that depend on it), according to `revdep("shiny")` from `{devtools}` [@R-devtools].

If you are very new to Shiny, this book might feel a little bit overwhelming: we will be discussing some advanced `{shiny}` and software engineering methods, best practices and structural idea for sending Shiny applications to production. 
This books relies on the assumption that you already know how to build basic Shiny applications, and that you want to push your Shiny skills to the next level: in other words, you are ready to move from the Proof of Concept to the production-grade application.
If you are very new to Shiny, we suggest you start with the [Mastering Shiny book](https://mastering-shiny.org/) before reading the present book.

Ready to start engineering production-grade Shiny Apps?

## What is a complex Shiny Application? {#complex-shiny}

> One of the unfortunate things about reality is that it often poses complex problems that demand complex solutions

`r right_link("The Art of Unix Programming", "http://www.catb.org/~esr/writings/taoup/html/ch13s01.html")`

### Reaching the cliff of complexity

Building a Shiny application seems quite straightforward when it comes to small prototypes or proof of concepts: after a few hours of practice and documentation reading, most R developers can have a small working application.  
But things change when your application reaches "the cliff of complexity"
^[We borrow this term from Charity Major, as heard in _Test in Production with Charity Majors_, [CoRecursive](https://corecursive.com/019-test-in-production-with-charity-majors/){target="_blank"}]
, _i.e_ that moment when the application reaches a states when it can be qualified as "complex".

But what do we mean by complexity? 
Getting a clear definition is not an easy task
^[Ironic, right?] 
as it very much depends on who is concerned and who you are talking to.
But a good definition can be found in _The DevOps Handbook_ [@genekim2016]: _"One of the defining characteristics of a complex system is that it __defies any single person's ability to see the system as a whole and understand how all the pieces fit together__. Complex system typically have a high degree of interconnectedness of tightly coupled components, and system-level behavior cannot be explained merely in terms of the behavior of the system components."_ (we underlined).

Or as noted in "Refactoring at Scale" [@lemaire2020], "_It becomes nearly impossible to reason about the effect a change might have when applied uniformly across a sprawling, complex system. Many tools exist to identify code smells or automatically detect improvements within subsections of code, but we are largely unable to automate human reasoning about how to restructure large applications,in codebases that are growing at an increasingly rapid pace._"

Building on top of these quotes, let's try to come up with a definition that will serve us in the context of engineering Shiny applications. 

When building software, we can think of complexity from two points of view: the complexity as it is seen by the developer, and the complexity as it is seen by the customer/end-user 
^[From _The Art of Unix Programming_, "Chapter 13: Speaking of Complexity", [@ericraymond2003]]
.

+ For the code, bugs are harder to anticipate: it is hard to think about all the different paths the software can follow and difficult to identify bugs because they are deeply nested in the numerous routines the app is doing. 
It is also hard to think about what the state of your app is at a given moment because of the numerous inputs and outputs your app contains. 

+ From the user perspective, the more complex an app is, the steeper the learning curve.
Indeed, the user will have to invest more time learning how the app works, and will be even more disappointed if ever they realize this time has been a waste.

Let's dive a little bit more in these two type of complexity.

#### Developers complexity

An app is to be considered complex when it is so large in terms of size and functionality that it makes it impossible to reason about it at once, and developer must rely on tools and methods to understand and handle this complexity: for example, when it comes to `{shiny}`, you will rely on tools like the `{golem}` [@R-golem] framework, introduced all along this book, to handle some implementation, development and deployment complexity.
This book will introduce a clear methodology that comes with a series of conventions, which are crucial when it comes to building and maintaining complex systems: by imposing a formalized structure for a software, it enhances its readability, lower the learning curve for new-comers, and reduces the risk of errors inherent to repetitive tasks.

This type of complexity is called _implementation complexity_. 
One of the goal of this book is to present you a methodology and toolkit that will help you reduce this form of complexity. 


#### Customers and users complexity

Customers and end users see complexity as _interface complexity_. 

Interface complexity can be driven by a lot of elements, for example the probability of making an error while using the app, the difficulty to understand the logical progression in the app, the presence of unfamiliar behavior or terms, visual distractions, etc.
This book will also bring you strategy to help you cope with the need for simplification when it comes to designing interface. 

### Balancing complexities

There is an inherent tension between these two sources of complexity, as designing an app means finding a good balance between implementation and interface complexity.
Lowering one source of complexity usually means increasing the other, and managing an application project means knowing where to draw the line.
This usually requires restraining yourself from implementing too much features, and still create an application that is easy to use, and that fits the requirements you have received. 

For example, there is something common in Shiny application: what we can call the "too much reactivity pattern". 
In some cases, developers try to make everything reactive: _e.g._, three sliders and a dropdown input, all updating a single plot.
This behavior lowers the interface complexity: users do not have to really think about what they are doing, they move sliders, change the inputs, and boom! the plot updates. 
But this kind of pattern can make the application perform too much computation, for example because users rarely go to the value they need on their first try: they usually miss what value they actually want to select. 

One solution can be to delay reactivity or to cache things so that R computes fewer things. 
But that comes with a cost: handling delayed reactivity and caching elements increase implementation complexity. 
Another solution is to add an "update plot" button, which updates the plot only when the user clicks on it. 
This pattern makes it easier to control reactivity from an implementation side. 
But this can make the interface a little bit more complex for the users, who have to perform another action, on top of changing their inputs. 
We will argue in this book that not enough reactivity is better than too much reactivity, as the latter increases computation time, and relies on the assumption that the user makes the right action on the first try.

Another good example is `{shiny}`'s `dateRangeInput()` function.
This function requires the user to choose a starting date and an ending date.
However, the function allows to choose a start date which is posterior to the end (that is the behavior of the JavaScript plugin used in `{shiny}` to create this input).
But allowing this behavior leads to bugs, notably in a context of full reactivity. 
Handling this special case is completely doable: with a little bit of craft, you can watch what the user inputs and throw an error if the start is after the end
^[See [shiny/issues/2043#issuecomment-525640738](https://github.com/rstudio/shiny/issues/2043#issuecomment-525640738){target="_blank"} for an example]
.
On one hand that solution increases implementation complexity, while on the other hand letting this naive behavior requires the user to think carefully about what they are selecting, thus increasing the interface complexity.

So what should we do? 
It's up to you: deciding where to draw the line between interface & implementation complexity very much depends of the project, but that is something that you should keep in mind all along the project's life.

### Assessing Code Complexity

On the developer side, you will want to reduce code complexity so that everybody involved in the coding process is able to create a mental model of how the application work.
On the user side, you will want to reduce interface complexity so that everybody comes out of using your application with a good user-experience.

Reducing complexity first comes with being able to identify its potential sources, be it in your application code base or in the specifications describing how the application should work.
Finding these sources of complexity is not an easy task, as it requires some programming knowledge to identify bottlenecks, basic UX (User Experience) skills to implement a good interface, and of course a project management methodology to structure the whole life of your application.

All these points will be addressed in this book.
But before that, let's dive into code complexity.

#### Codebase size

The total number of lines of code, or the number of files, can be good clue of potential complexity, but only if used as order of magnitude (for example a 10,000-line codebase is potentially more complex than a 100-line codebase), but should not be relied on if used strictly, even more if you try to reduce this number of line by sacrificing code readability.

R is very permissive when it comes to indentation and line breaks, and, unlike JavaScript or CSS, it is generally not minified
^[The minification process is the process of removing all blank characters and put everything on one line so that the file in the output is much smaller.]
.  
In R, the number of lines of code depends on your coding style and the packages you are using. 
For example, the `{tidyverse}` [@tidyverse2019] style guide encourages the use of `%>%` (called "pipe"), with one function by line, producing more lines in the end code: "_`%>%` should always have a space before it, and should usually be followed by a new line_" [tidyverse style guide](https://style.tidyverse.org/pipes.html){target="_blank"}.
So you can expect a "tidyverse-centric" package to contain more lines of code, yet the pipe itself has been thought as a tool to lower code complexity by enhancing its readability^[Note though that some users find using the pipe more complex than not.].

For example, the two following pieces of code do the same thing. 
Both have a different number of lines, and a different level of reading complexity.

```{r 01-big-shiny-1 }
library(dplyr, warn.conflicts = FALSE)
# With pipe
iris %>%
  group_by(Species) %>%
  summarize(m_sp = mean(Sepal.Length))
# Without
summarize(group_by(iris, Species), m_sp = mean(Sepal.Length))
```

Also, there is also no limit in the way you can indent your code. 

```{r 01-big-shiny-2 }
iris[
  1
  :
    5, 
  "Species"
]
```

Six lines of code for something that could also be written in one line.  

```{r 01-big-shiny-3 }
iris[1:5, "Species"]

```

In other words, using this kind of writing style can make the code base larger in term of lines, without really adding complexity to the general program. 

Another drawback of this metric is that it focuses on numbers instead of readability, and in the long run, yes, readability matters.
As noted in _The Art of Unix Programming_ [@ericraymond2003], "Chapter 13: Speaking of Complexity", "_Pressure to keep the codebase size down by using extremely dense and complicated implementation techniques can cause a cascade of implementation complexity in the system, leading to an un-debuggable mess_".

Still, this metric can be useful to reinforce what you have learned from other metrics.
It is rather unlikely that you will find this "extreme" coding style we showed above, and even if it might not make sense to compare two codebases that just differ by 1 or 2 % of lines of code, it is very likely that a codebase which is ten, one hundred, one thousand times larger is a more complex software. 

Another good metric related to code complexity is the number of files in the project: R developers tend to split their functions into several files, so the more files you will find in a project, the larger the codebase is. 
And numerous files can also be a sign of maintenance complexity, as it may be harder to reason about an app logic split into several files than about something that fits into one linear code inside one file
^[
To handle the complexity of splitting into files, you can set filenames to follow the structure of the project. This pattern is developed in another part of this book, where we explicit the conventions used in `{golem}`.
]. 
On the other hand, one big 10,000-lines file which is standing alone in the project is not a good sign either. 

If you want to use the number of lines metric, you can do it from R with the `{cloc}` [@R-cloc] package, available at <https://github.com/hrbrmstr/cloc>.

```{r 01-big-shiny-4, include = FALSE}
if (!requireNamespace("cloc")){
  remotes::install_github("hrbrmstr/cloc")
}
```

```{r 01-big-shiny-5, eval = FALSE}
remotes::install_github("hrbrmstr/cloc")
```

For example, let's compare a rather big package (`{shiny}`) with a small one (`{attempt}` [@R-attempt]):

```{r 01-big-shiny-6 }
library(cloc)
library(dplyr)
shiny_cloc <- cloc_cran(
  "shiny", 
  .progress = FALSE, 
  repos = "http://cran.irsn.fr/"
)
attempt_cloc <- cloc_cran(
  "attempt", 
  .progress = FALSE, 
  repos = "http://cran.irsn.fr/" 
)
clocs <- bind_rows(
  shiny_cloc, 
  attempt_cloc
)

# Counting lines of code
clocs %>%
  group_by(pkg) %>%
  summarise(
    loc = sum(loc)
  )

# Counting files
clocs %>%
  group_by(pkg) %>%
  summarise(
    files = sum(file_count)
  )

```

Here, with these two metrics, we can safely assume that `{shiny}` is a more complex package than `{attempt}`.

#### Cyclomatic complexity

Cyclomatic complexity is a software engineering measure which allows to define the number of different linear paths a piece of code can take.
The higher the number of paths, the harder it can be to have a clear mental model of this function. 

Cyclomatic complexity is computed based on a control-flow graph
^[A control flow graph is a graph representing all the possible paths a piece of code can take while it is executed.] 
representation of an algorithm. 
For example, here is a simple control flow for an `ifelse` statement:

(ref:controlflowcap) Control-flow graph representation of an algorithm.

```{r 01-big-shiny-1-bis, echo=FALSE, fig.cap="(ref:controlflowcap)", out.width='100%'}
knitr::include_graphics("img/controlflow.png")
```

_(The following paragraph details the algorithm implementation, feel free to skip it if you are not interested in the implementation details)_  
The complexity number is then computed by taking the number of nodes, subtracting the number of edges, and adding twice the number of connected components of this graph. 
The algorithm is then $M = E − N + 2P$, where $M$ is the measure, $E$ the number of edges, $N$ the number of nodes and $2P$ is twice the number of connected components.
We will not go deep into this topic, as there are a lot things going on in this computation and you can find many documentation about this online.
Please refer to the bibliography for further readings about the theory behind this measurement. 

In R, the cyclomatic complexity can be computed using the `{cyclocomp}` [@R-cyclocomp] package.
You can get it from `CRAN` with:

```{r 01-big-shiny-7, include=FALSE}
# for writers
if (!requireNamespace("cyclocomp")) {install.packages("cyclocomp")}
```

```{r 01-big-shiny-8, eval = FALSE}
install.packages("cyclocomp")
```

The `{cyclocomp}` package comes with three main functions: `cyclocomp()`, `cyclocomp_package()`, and `cyclocomp_package_dir()`. 
While developing your application, the one you will be interested in is `cyclocomp_package_dir()`: building successful shiny apps with the `{golem}` framework means you will be building your app as a package (we will get back on that later).

Here is for example the cyclomatic complexity of the default golem template (assuming it is located in a `golex/` subdirectory):

```{r 01-big-shiny-9, include = FALSE}
#remotes::install_local("golex", upgrade = "never")
```

```{r 01-big-shiny-11, eval=FALSE}
library(cyclocomp)
cyclocomp_package_dir("golex") %>% head()
```

```{r 01-big-shiny-12, echo=FALSE}
cyclo_golex <- readr::read_rds(here::here("dataset", "cyclo_golex.rds"))
head(cyclo_golex)
```

```{r 01-big-shiny-13, include = FALSE}
#remove.packages("golex")
```

And the one from another small application:

```{r 01-big-shiny-14, include = FALSE}
if (!requireNamespace("tidytuesday201942")) {
  remotes::install_github("ColinFay/tidytuesday201942")
}
```


```{r 01-big-shiny-15, eval=FALSE}
cyclocomp_package("tidytuesday201942") %>% head()
```

```{r 01-big-shiny-16, echo=FALSE}
cyclo_tidytuesday <- readr::read_rds(here::here("dataset", "cyclo_tidytuesday.rds"))
head(cyclo_tidytuesday)
```

And, finally, the one for `{shiny}`:

```{r 01-big-shiny-17, include = FALSE}
if (!requireNamespace("shiny")) {
  remotes::install_cran("shiny")
}
```

```{r 01-big-shiny-18, eval=FALSE}
cyclocomp_package("shiny") %>% head()
```

```{r 01-big-shiny-19, echo=FALSE}
cyclo_shiny <- readr::read_rds(here::here("dataset", "cyclo_shiny.rds"))
head(cyclo_shiny)
```

And, bonus, this `cyclocomp_package()` function can also be used to retrieve the number of functions inside the package.


So, as The Clash said, "what are we gonna do now?" 
You might have heard this saying: "if you copy and paste a piece of code twice, you should write a function", so you might be tempted to do that. 
Indeed, splitting code into smaller pieces lowers the local cyclomatic complexity, as smaller functions have lower cyclomatic complexity. 
But that is just at a local level, and it can be a suboptimal option: having a very large number of functions can make it harder to navigate through the codebase.
In the end of the day splitting into smaller functions is not a magic solution because (A) the global complexity of the app is not lowered by splitting things into pieces (just local complexity), and (B) the deeper the call stack, the harder it can be to debug. 

#### Other measures for code complexity

Complexity can come from other sources: insufficient code coverage, dependencies that breaks the implementation, relying on old packages, or a lot of other things. 

We can use the `{packageMetrics2}` [@R-packageMetrics2] package to get some of these metrics: for example, the number of dependencies, the code coverage, the number of releases and the date of the last one, etc., ... and the number of lines of code and the cyclomatic complexity.

```{r 01-big-shiny-20, include = FALSE}
if (!requireNamespace("packageMetrics2")) {
  remotes::install_github("MangoTheCat/packageMetrics2")
}
```

```{r 01-big-shiny-21 }
library(packageMetrics2)
frame_metric <- function(pkg){
  metrics <- package_metrics(pkg)
  tibble::tibble(
    n = names(metrics), 
    val = metrics, 
    expl = list_package_metrics()[names(metrics)]
  )
}
```

```{r 01-big-shiny-22, echo=FALSE, eval=FALSE}
db <- memoise::cache_filesystem(here::here("fcache/"))
frame_metric <- memoise::memoise(frame_metric, cache = db)
```

*{golem}*

```{r 01-big-shiny-23, cache=TRUE, warning=FALSE, eval=FALSE}
frame_metric("golem") %>% knitr::kable()
```
```{r 01-big-shiny-24, echo=FALSE}
frame_golem <- readr::read_rds(here::here("dataset", "frame_golem.rds"))
knitr::kable(frame_golem)
```

*{shiny}*

```{r 01-big-shiny-25, cache=TRUE, warning=FALSE, eval=FALSE}
frame_metric("shiny") %>% knitr::kable()
```

```{r 01-big-shiny-26, echo=FALSE}
frame_shiny <- readr::read_rds(here::here("dataset", "frame_shiny.rds"))
knitr::kable(frame_shiny)
```

If you are building your Shiny application with `{golem}`, you can use the `DESCRIPTION` file, which contains the list of dependencies, as a starting point to explore these metrics for your dependencies, for example using `{desc}` [@R-desc] or `{attachment}` [@R-attachment]:

```{r 01-big-shiny-27 }
desc::desc_get_deps("golex/DESCRIPTION")
# See also 
attachment::att_from_description("golex/DESCRIPTION")
```

### Production Grade Software Engineering

Complexity is still frowned upon by a lot of developers, notably because it has been seen as something to avoid according to the Unix philosophy. 
But there are dozens of reasons why an app can become complex: for example, the question your app is answering is quite complex and involves a lot of computation and routines. 
The resulting app is rather ambitious and implements a lot of features, etc.
So yes, there is a chance that if you are reading this page, you are working or are planning to work on a complex Shiny app. 
And this is not necessarily a bad thing! 
Shiny apps can definitely be used to implement production-grade
^[By production-grade, we mean a software that can be used in a context where people use it for doing their job, and where failures or bugs have real-life consequences.] 
software, but production-grade software implies production-grade software engineering. 
To make your project a success, you need to use tools that reduce the complexity of your app and ensure that your app is resilient to aging. 

In other words, production-grade Shiny apps requires working with a software engineering mindset, which is not always an easy task in the R world: many R developers have learned this language as a tool for doing data analysis, building model, making statistics, not really as a tool for building software.

The use of R has evolved since its initial version released in 1995, and using this programming language as a tool to build software for production is still a challenge, even `r lubridate::year(Sys.Date()) - 1995` years after its first release.
And still today, for a lot of R users, the software is still used as an "experimentation tool", where production quality is one of the least concerns. 
But the rise of `{shiny}` (among other packages) has drastically changed the potential of R as a language for production software engineering: its ease of use is also one of the reason why the language is now used outside academia, in more "traditional" software engineering teams.

This changing context requires different mindsets, skills, and tools. 

With `{shiny}`, as we said before, it is quite easy to prototype a simple app, without any "hardcore" software engineering skills. 
And when we are happy with our little proof of concept, we are tempted to add something new. 
And another. 
And another. 
And without any structured methodology, we are almost certain to reach the cliff of complexity very soon and end up with a codebase that is hardly (if ever) ready to be refactored to be sent to production. 

The good news is that building a complex app with R (or with any other language) is not an impossible task. 
But this requires planning, rigor, and correct engineering. 
This is what this book is about: how to organize your Shiny App in a way that is time and code efficient, and how to use correct engineering to make your app a success.

## What is a successful Shiny App? 

Defining what "successful" means is not an easy task, but we can extract some common patterns when it comes to applications that would be considered successful. 

### It exists

First of all, an app is successful if it was delivered.
In other words, the developer team was able to move from specification to implementation to testing to delivering. 
This is a very engineering-oriented definition of success, but it is a pragmatic one: an app that never reaches the state of usability is not a successful app, and something along the way has blocked the process of finishing the software. 

This condition implies a lot of things, but mostly it implies that the team members were able to organize themselves in an efficient way, so that they were able to work together in making the project a success. 
Anybody that has already worked on a code base as a team knows it is not an easy task.

### It is accurate

The project is a success if the application was delivered, and if it answers the question it is supposed to answer, or serves the purpose it is supposed to serve. 
Delivering is not the only thing to keep in mind: you can deliver a working app but it might not work the way it is supposed to work.

Just as before, accuracy means that between the moment the idea appears in someone's mind and the moment the app is actually ready to be used, everybody was able to work together toward a common goal, and that now this goal is reached, we are also certain that the answers we get from the application are accurate, and that users can rely on the application to make decision. 

### It is usable

Being usable means that the app was delivered, it serves the purpose, and it is user-friendly.

Unless you are just coding for the joy of coding, there will always be one or more end users. 
And if these people cannot use the application because it is too hard to use, too hard to understand, because it is too slow or there is no inherent logic in how the user experience is designed, then it is inappropriate to call the app a success. 

### It is immortal

Of course "immortal" is a little bit far fetched, but when designing the application, you should aim for robustness along the years, by engineering a (theoretically) immortal application. 

Planning for the future is a very important component of a successful Shiny App project.
Once the app is out, it is successful if it can exist in the long run, with all the hazards that this implies: new package versions that could potentially break the code base, sudden call for the implementation of new features in the global interface, changing key features of the UI or the back-end, and not to mention passing the code base along to someone who has not worked on the first version, and who is now in charge of developing the next version
^[In fact, this new person might simply be you, a month from now. And _"You'll be there in the future too, maintaining code you may have half forgotten under the press of more recent projects. When you design for the future, the sanity you save may be your own._ [@ericraymond2003].
]
. 
And this, again, is hard to do without effective planning and efficient engineering. 

