# (PART) Step 4: Strengthen {-}

# Build yourself a safety net {#step-secure}

> "Don't fuck over Future You"

> JD 

Strengthening your app means two things: testing, and locking the application environment.

## Testing your app

### Testing the business logic

If you have been following the good practices we have listed in previous chapters, your current application has at least these two properties: 

+ The business-logic functions are separated from your interactive-logic functions.
+ Your application is inside a package.

On top of being a sane organization approach, using this separation inside a package structure allows to leverage all the tooling that has been built for testing "standard" packages. 

R developers have been developing packages for a long time, and at the time of writing these lines (February 2020), more than 15,000 packages are available on CRAN. 
To sustain these developments, a lot of tooling has been created to secure the development process, and especially in the field of creating unit tests for your package.

Unit tests are a general concept in software engineering that describes the process of writing a form of assessment of your code validity. 
A simplified explanation is that if you write a function call `meaning_of_life` that returns `42`, you will expect this function to always return `42`, and to be alerted if ever this value changes. 
Using unit tests is a way to secure your work in the future, be it from future you or from collaborator: if anyone comes and change the code behind `meaning_of_life` so that the result is no longer `42`, the developer working on this piece of code will be able to catch it. 

There are several packages in R that can be used to implement unit testing, and you can even implement your own tests. 
One of the most popular right now^[
Based on the number of Reverse dependencies & suggests at https://cran.r-project.org/web/packages/testthat/index.html
] is [`{testthat}`](https://testthat.r-lib.org/), by Hadley Wickham.
This testing framework lets you write a series of tests and expectations, which are then launch when calling `devtools::test()`, either locally or in you CI system. 
Here is an example of testing that the `meaning_of_life` will always be `42`.

``` r
test_that("The meaning of life is 42", {
  expect_equal(
    meaning_of_life(), 
    42
  )
})
```

If you want to learn more about how to use `{testthat}`, you can refer to the following resources: 

+ [`{testthat}` online documentation](https://testthat.r-lib.org/)

+ [Chapter 10 Testing - R Packages](https://r-pkgs.org/tests.html)

+ [Part 5: Test and Code Coverage - Building a package that lasts — eRum 2018 workshop](https://speakerdeck.com/colinfay/building-a-package-that-lasts-erum-2018-workshop?slide=107)


### Testing the interactive logic

Once you have built a solid test suite for your business logic, another side of your app you might want to check is the interactive logic, i.e. the user interface. 

There are several tools from the web developer world that can be used to do exactly that: mimicing an interactive session where instead of deliberately clicking on the application interface, you let a program do it for you. 
That's for example the job for `puppeteer`, which is a NodeJS module that drives a Google Chrome headless session and mimic a session on the app. 

And good news, there is a Google Chrome extension, called [Puppeteer Recorder](), that allows you to create, while visiting a webpage, the `pupepeteer` script to reproduce your visit. 
Here is, for example, a very small script for testing `{hexmake}`, generated by this extension.

``` javascript
const puppeteer = require('puppeteer');
(async () => {
  const browser = await puppeteer.launch()
  const page = await browser.newPage()
  
  await page.goto('http://localhost:2811/')
  
  await page.setViewport({ width: 1440, height: 766 })
  
  await page.waitForSelector('.row > .col > .rounded > details:nth-child(3) > summary')
  await page.click('.row > .col > .rounded > details:nth-child(3) > summary')
  
  await page.waitForSelector('.innerrounded #main_ui_1-left_ui_1-pkg_name_ui_1-package')
  await page.click('.innerrounded #main_ui_1-left_ui_1-pkg_name_ui_1-package')
  
  await browser.close()
})()
```

Once you have this piece of code, put it into a NodeJS script, and replay the session as many time as you need.
If ever one of the step can't be replayed as recorded, the script will fail, notifying you of a regression.

Several packages in R mimic what `puppeteer` does (Google Chrome headless orchestration), with notably `{crrri}` and `{chromote}`.
These packages can also be used to launch an manipulate a Google Chrome headless session, meaning that you can programmatically navigate and interact with a webpage from R.  

Finally, if you're looking for a Shiny specific package, you can go for `{shinytest}`. 
This package, created and maintained by RStudio, allows you to do a series of screenshots of your application, and then replays your app and compare the previously taken screenshots to the current states of your application, allowing you to detect any changes in the interface. 

Here is for example how it would work with a `{golem}` based application: 

```{r 12-step-by-step-secure-1, eval = FALSE}
golem::add_rstudioconnect_file()
shinytest::recordTest()
```

Once this function is run, a new window opens: it contains your app, and a "Screenshot" button on the right. 
Using this button, you can take various recording of your shiny application at different states. 

![](img/shinytest.png)

Then, you can do some changes in your app, and run:

```{r 12-step-by-step-secure-2, eval = FALSE}
shinytest::testApp()
```

If the `{shinytest}` package detects a visual change in the application, you will be immediately alerted, with a report of the difference from the snapshots you took and the current state of the application. 

### Testing the app load

```{r 12-step-by-step-secure-1-bis, include=FALSE, error=TRUE}
try({system("docker rm hexmake")})
```

#### `{shinyloadtest}`

`{shinyloadtest}`, on the other hand, tests how an application behaves when one, two, three, twenty, one hundred users connect to the app, and gives you a visual report about the connection and response time of each session.
The idea with `{shinyloadtest}` is to first record a session where you mimic a user behaviour, then `shinycannon`, a command line tool coming with `{shinyloadtest}`, replays the recording several times. 
Once the session has been replayed several times mimicing the session you've recorded, you have access to a report of the behavior of your app. 

```{r 12-step-by-step-secure-3}
library(shinyloadtest)
```

```{r 12-step-by-step-secure-4, eval = FALSE}
# Starting your app in another process
p <- processx::process$new(
  "Rscript", c("-e", "options('shiny.port'= 2811);hexmake::run_app()")
)
# Check that the process is alive
Sys.sleep(5) # We wait for the app to be ready
p$is_alive()
browseURL("http:://localhost:2811")
```

Record the tests, potentially in a new dir: 

```{r 12-step-by-step-secure-5, eval = FALSE}
fs::dir_create("shinylogs")
withr::with_dir(
  "shinylogs", {
    shinyloadtest::record_session("http://localhost:2811", port = 1234) 
  }
)
```

We now have a series of one or more recording(s) inside the `shinylogs/` folder: 

Then, let's switch to our command line, and rerun the session with `shinycannon`. 
The `shinycannon` command line tools take several argument: the path the `.log` file, the url of the app, `--workers` specify the number of concurrent connections to run, and the `--output-dir` argument specifies where the report should be written. 

```{bash 12-step-by-step-secure-6, eval = FALSE}
shinycannon shinylogs/recording.log http://localhost:2811 --workers 10 --output-dir shinylogs/run1
```

And now, we have new files inside the folder, corresponding to the session recordings. 

```{r 12-step-by-step-secure-7}
fs::dir_tree("shinylogs", recurse = FALSE)
```

Good news: we do not have to manually analyse these files—`{shinyloadtest}` offers a series of wrapper functions to do that. 

```{r 12-step-by-step-secure-8, message = FALSE}
shinyload_runs <- shinyloadtest::load_runs("5 workers" = "shinylogs/run1")
```

We now have a data.frame with 

```{r 12-step-by-step-secure-9}
dplyr::glimpse(shinyload_runs)
```

Then, `{shinyloadtest}` comes with a series of plotting functions that can be used to analyse your recording. 
Here are some examples:

+ `slt_session_duration()` plots the session duration, with the various types of event that takes computation time: JS and CSS load, R computation... 

```{r 12-step-by-step-secure-10}
slt_session_duration(shinyload_runs)
```

+ `slt_waterfall()` plots the waterfall graph of session durations, ordered by events. 

```{r 12-step-by-step-secure-11}
slt_waterfall(shinyload_runs)
```

And if you need to bundle everything into an HTML reports, `shinyloadtest_report()` is what you're looking for. 

```{r 12-step-by-step-secure-12, eval = FALSE}
shinyloadtest_report(shinyload_runs)
```

So, to sum up with a step by step guide:

+ If the shiny app is only available on your machine, launch a process with `{processx}`, or in another R session, that launches the application. 
You can either set the port with `options('shiny.port'= 2811)`, or let shiny decide for you. 
Be sure that the process is running. 
If the app is online, use the online url (and make sure you have access to the app).

+ Run `shinyloadtest::record_session(url)`. 
You should probably set a different port for `{shinyloadtest}`, so that it doesn't try to connect on port 80. 

+ Play around with your app, record a scenario of usage

+ Close the tab where the app is running. 

+ Return to your terminal, and run the `shinycannon` command line tool

+ Wait for the process to be terminated

+ Go back to R, and then you can analyse the data from the recordings, either manually or by generating the html report 

#### `{shinyloadtest}` & `{dockerstats}`

Another thing you might want to monitor is the memory / CPU usage of your application, which `{shinyloadtest}` doesn't natively provide: the package records the load from the browser point of view, not from the server one. 
That's where `{dockerstats}` can come into play: this package is a wrapper around the command line `docker stats`, and returns an R data.frame with the stats. 

You can get the `{dockerstats}` package from GitHub with:

```{r 12-step-by-step-secure-13, eval = FALSE}
remotes::install_github("ColinFay/dockerstats")
```

With these stats, we can monitor the load on the app when it's run in a docker container. 

```{r 12-step-by-step-secure-14, echo = FALSE, error = TRUE}
system("docker run --name hexmake --rm -p 2811:80 colinfay/hexmake", wait = FALSE)
Sys.sleep(5)
```

```{r 12-step-by-step-secure-15, eval = FALSE}
system("docker run --name hexmake --rm -p 2811:80 colinfay/hexmake", wait = FALSE)
```

Let's say now we want the stats for the hexmake container:

```{r 12-step-by-step-secure-16}
dockerstats::dockerstats("hexmake")
```

Of course, right now we are not using the app, so the usage can be pretty small. 
But let's push it a little bit an mimic a lot of connexions: to do that, we can replay our `shinycannon` call, with at the same time using the `dockerstats_recurse()` function, that will recursively call `dockerstats()` on a regular interval. 

```{r 12-step-by-step-secure-17, include = FALSE}
try({fs::dir_delete("shinylogs/run2")})
```

```{bash 12-step-by-step-secure-18, eval = FALSE}
shinycannon shinylogs/recording.log http://localhost:2811 --workers 10 --output-dir shinylogs/run2
```

And let's launch at the same time a `dockerstats_recurse()`
For example, here, we will be printing, on each loop, the `MemUsage` of the container, then saving the data inside a `dockerstats.csv` file. 

```{r 12-step-by-step-secure-19, eval = FALSE}
dockerstats_recurse(
  "hexmake",
  callback = function(res){
    print(
      paste("Mem usage: ", res$MemUsage)
    )
    write.table(
      res, 
      "dockerstats.csv", 
      append = TRUE, 
      col.names = FALSE, 
      row.names = FALSE, 
      sep = ","
    )
  }
)
```

Here is what both look side to side:

![](img/hexmake-dockerstats.png)

As you can see, as the number of connections grow, the memory usage grows. 
And we now have a csv with the evolution of the `docker stats` records over time:

```{r 12-step-by-step-secure-20}
docker_stats <- readr::read_csv(
  "shinylogs/dockerstats.csv", 
  col_names = names(
    dockerstats::dockerstats()
  )
)
```

```{r 12-step-by-step-secure-21}
dplyr::glimpse(docker_stats)
```

```{r 12-step-by-step-secure-2-bis, include=FALSE}
try({system("docker rm hexmake")})
```



## A reproducible environment

One of the challenges of building an app that needs to be sent to production is that you will need to work in a reproducible environment. 
What does that mean?
That you are building an application that is to be deployed in another "computer" than yours. 
Indeed, once your app is built, there are few chances that you will launch it on your computer and that external user will connect to your computer. 
What will happen is that you will either give your user a package (which will be the simplest way to share it: bundle the app into a package, then let people install it either manually or from a package repository), or a url where they can connect and use your app. 

In that second case, you will have to think about how you can create your app in a reproducible environment: in other words, be sure that the app is deployed under the same configuration as your local application—R version, package versions, system requirements, environment variables...

To achieve that, we will introduce you to two tools to do that: `{renv}`, and Docker.

### {renv} 

#### About {renv} 

How do we make sure the package versions we have installed on our machine stays the same in the production environment? 
And also, how can we be sure that, working as a team, we'll be able to work together using the same package version? 

From one version to another, functions and behaviors change. 
Most of the time, new version means new functions, and new features. 
But from time to time, a new version means breaking changes. 
And of course, catching that these new versions cause breaking changes can be hard to catch: either because we do not realize that the version is different, or because debugging the error is difficult, especially in Shiny where the trace-back is very deep. 
For example, here is an error from a real life error when pushing an app on a shiny-server: 

``` bash
root@westeros-vm:/var/log/shiny-server# cat thewall(...).log
*** caught segfault ***
[...]
address 0x5100004d, cause 'memory not mapped'

Traceback:
1: rcpp_sf_to_geojson(sf, digits, factors_as_string)
2: sf_geojson.sf(data)
3: geojsonsf::sf_geojson(data)
4: addGlifyPolygons(., data = pol_V1, color = les_couleurs, popup = "val", opacity = 1)
5: function_list[[i]](value)
6: freduce(value, `_function_list`)
7: `_fseq`(`_lhs`)
8: eval(quote(`_fseq`(`_lhs`)), env, env)
[...]
105: captureStackTraces({    while (!.globals$stopped) {        ..stacktracefloor..(serviceApp())        Sys.sleep(0.001)    }})
106: ..stacktraceoff..(captureStackTraces({    while (!.globals$stopped) {        ..stacktracefloor..(serviceApp())        Sys.sleep(0.001)    }}))
107: runApp(Sys.getenv("SHINY_APP"), port = port, launch.browser = FALSE)
An irrecoverable exception occurred. R is aborting now ...
```

Pretty hard to debug, isn't it? 
So, what has actually happened? 
It turned out that the package version from `{geojsonsf}` was `1.2.1`, and the one on the Shiny server was `1.3.0`. 
And there was a breaking change in the package. 

![](img/geojson.png)

The same thing could have happen if working as a team: one of the computer has an old version, when another one has updated to a more recent one. 
How do we prevent that? 
This is where the `{renv}` package comes into play: this package allows to have a project-based library, instead of a global one. 
In other words, instead of having a library that is global to your machine, `{renv}` allows to specify packages with fixed version for a project. 
That means that you can have `{geojsonsf}` version `1.2.1` in one of your project, and the `1.3.0` in another, with the two not conflicting with each other. 

#### Using {renv} 

> Underlying the philosophy of renv is that any of your existing workflows should just work as they did before

`r right_link("Introduction to renv", "https://rstudio.github.io/renv/articles/renv.html")`

The first thing to do with `{renv}` is initiating it with the `init()` function. 

<<<<<<< HEAD
```{r 12-step-by-step-secure-22, eval = FALSE}
=======
```{r eval = FALSE}
>>>>>>> a85bd2fe5fa65dc964bfaef536a18960b40c7c3d
renv::init()
```


<<<<<<< HEAD
```{r 12-step-by-step-secure-23, eval = FALSE}
=======
```{r eval = FALSE}
>>>>>>> a85bd2fe5fa65dc964bfaef536a18960b40c7c3d
renv::init(here::here("golex"), restart = FALSE)
```

What this does is initiating a new `Lockfile` inside your project, listing the packages versions and linking it to your computer cache.
Note that these packages can come from CRAN, Bioconductor, GitHub, Gitlab, 
Bitbucket, and even local repositories.

And now, when you need a new package, you will need to install it in your local library.
The fastest way to install new packages is by using the `install.packages` function, which is shimmed by `{renv}`. 
This shim will search into the local cache to see if the package has already been cached.


```{r 12-step-by-step-secure-24, eval = FALSE}
```{r eval = FALSE}
install.packages("dplyr")
```

Once you want to update your `{renv}` `Lockfile`, call `snapshot()`

```{r 12-step-by-step-secure-26, eval = FALSE}
renv::snapshot()
```

```{r 12-step-by-step-secure-27, eval = FALSE}
renv::snapshot(here::here("golex"), restart = FALSE)
```

And now that you have a reproducible `{renv}` library, what is next? 
Of course, if you are either working as a team or deploying to a server, you will have to restore the state of your project, which is now living somewhere else, inside your current project / deployment. 
And to do that, the function to call is `env::restore()`, which will update your local project with the dependencies listed inside your `Lockfile`. 

So, to sum up, here are the step to follow: 

+ Init the project with `renv::init()`
+ Install / remove packages 
+ Take a `snapshot()` of the state of your project 
+ `restore()` the state of your project using the `Lockfile`

Of course, `renv::restore()` comes with another superpower: time travelling! 
If you work on a project and decide to update a package you have been using, and realize that this package makes the application crash (for example, as the update to `{geojsonsf}` made our application crash), you can go back in time to a previous version of your library by calling the `restore()` function. 

There are more things you can do with `{renv}`. 
If you want to know more, feel free to refer to the [official website](https://rstudio.github.io/renv).

### Docker 

#### R, Docker, Shiny

Docker is a program that allows to download, install, create, launch and stop multiple operating systems, called containers, on a machine, which will be called the host.
This host can be your local computer, or the server where you are deploying your application. 

Docker was designed for enclosing software environments inside an image that can later be launch. 
The general idea is that with Docker, you're defining in a `Dockerfile` all the "rules" that are used to create a given environment, and then you can use this file (and the linked files, for example the R package containing your app) to deploy your application on any giver server that can run Docker. 
That way, if the `Dockerfile` can compile on your machine and if you can run it, it should work everywhere (of course, it's a little bit more complex than that, but you have got the idea). 

So, why Docker in the context of Shiny apps? 
Because Docker allows you to abstract away the complexity of managing multiple versions of R and multiple version of the same package, or even different versions of the same system requirement. 
By using Docker for your deployment, you can build and deploy an application with the very same version of packages and R as the one from your computer. 
That way, if your are building your application with an older version of `{shiny}`, you are sure that sending it to production won't break everything: the version inside the Docker is the same as the one from your machine. 
And later, if you update `{shiny}` and start a new project, you can deploy your app with another version of the package. 
Same goes for your version of R. 

#### Building a Dockerfile for your app

Good news! 
If you are building your app with `{golem}`, the creation of the `Dockerfile` is just one function away! 
If you have a look at the `03_deploy.R` file in the `dev` folder, you will find a series of functions that can create the `Dockerfile` for your project. 

Let's take some time to understand what this file contains, or how we could be building it from scratch.


1. `FROM`

```{r 12-step-by-step-secure-28, echo = FALSE}
readLines("Dockerfile")[1] %>% 
  glue::as_glue()
```

This line defines what version of R to use for deploying your application. 
This `FROM` line is the one that sets an image to start from: you rarely (if ever) build a Docker image from nothing, but instead you use an existing image on top of which you build your own image.
Here, we choose one of the [r-ver](https://hub.docker.com/r/rocker/r-ver/) docker images, based on the output of:

```{r 12-step-by-step-secure-29}
R.Version()$version.string
```

2. `RUN`

The `RUN` calls in the file refers to bash calls we are making to build the image. 
For example, the second line of the `Dockerfile` installs all the system requirements needed to your application.

```{r 12-step-by-step-secure-30, echo = FALSE}
readLines("Dockerfile")[2] %>% 
  glue::as_glue()
```

In the subsequent `RUN` calls, we are using `remotes::install_version()` to be sure we install the version that matches the one from your machine. 

```{r 12-step-by-step-secure-31, echo = FALSE}
readLines("Dockerfile")[6] %>% 
  glue::as_glue()
```

As you can see, it matches the local version: 

```{r 12-step-by-step-secure-32}
packageVersion("config")
```

3. `ADD`

This Docker entry takes a folder or a file, and copies it inside the image. 
With `{golem}`, we are adding the current project, containing the app, to a folder called `/build_zone`. 

```{r 12-step-by-step-secure-33, echo = FALSE}
readLines("Dockerfile")[13] %>% 
  glue::as_glue()
```

4. `EXPOSE`

This command defines which port of the container will be available from the outside of the container.

```{r 12-step-by-step-secure-34, echo = FALSE}
readLines("Dockerfile")[16] %>% 
  glue::as_glue()
```

5. `CMD`

This final command is the one that is launched when you run a container. 
With a `{shiny}` app, this command is the one that launches the application.  

```{r 12-step-by-step-secure-35, echo = FALSE}
readLines("Dockerfile")[16] %>% 
  glue::as_glue()
```

#### Read more about Docker 

+ [An Introduction to Docker for R Users](https://colinfay.me/docker-r-reproducibility/)

+ [An Introduction to Rocker: Docker Containers for R](https://journal.r-project.org/archive/2017/RJ-2017-065/RJ-2017-065.pdf)

+ [The Rockerverse: Packages and Applications for Containerization with R](https://arxiv.org/abs/2001.10641)
